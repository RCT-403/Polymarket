{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to Extract the tweet times from elonmusk.csv \n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def clean_line(line): # Get the last two lines while cleaning the weird characters\n",
    "    new_line = re.sub(r'[^\\w\\s,:\"]', '', line) \n",
    "    if len(new_line.split(',')) < 2: \n",
    "        return ' '\n",
    "    second_last_entry = new_line.split(',')[-2] \n",
    "    last_entry = new_line.split(',')[-1]\n",
    "    return second_last_entry + last_entry  \n",
    "\n",
    "def starts_and_ends_with_quote(s):\n",
    "    return s.strip().startswith('\"') and s.strip().endswith('\"')\n",
    "\n",
    "# Read the CSV file with the specified encoding\n",
    "with open('elonmusk.csv', 'r', encoding='utf-8', errors='ignore') as file: # Filters the bad characters\n",
    "    lines = file.readlines()\n",
    "\n",
    "cleaned_lines = [clean_line(line) for line in lines[1:]] \n",
    "filtered_lines = [line.lstrip() for line in cleaned_lines if starts_and_ends_with_quote(line)] # Filters only the time-stamps\n",
    "final_lines = [line for line in filtered_lines if len(line) < 26] # Removes all the non-time stamps\n",
    "\n",
    "# Write the modified lines back to the CSV file\n",
    "with open('fitlered_times.csv', 'w', encoding='utf-8') as file:\n",
    "    file.writelines(final_lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to Extract the IDS from elonmusk.csv\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def clean_line(line):\n",
    "    # Remove ambiguous characters but keep spaces, newlines, and commas\n",
    "    new_line = re.sub(r'[^\\w\\s,:\"]', '', line)\n",
    "    \n",
    "    # Split the cleaned line by commas and get the last entry\n",
    "    first_entry = new_line.split(',')[0]\n",
    "    return first_entry + '\\n'\n",
    "\n",
    "def has_19_digits(s):\n",
    "    return bool(re.match(r'^\\d{19}$', s.strip()))\n",
    "\n",
    "# Read the CSV file with the specified encoding\n",
    "with open('elonmusk.csv', 'r', encoding='utf-8', errors='ignore') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Clean each line\n",
    "cleaned_lines = [clean_line(line) for line in lines[1:]]\n",
    "filtered_lines = [line for line in cleaned_lines if has_19_digits(line)]\n",
    "\n",
    "# Write the modified lines back to the CSV file\n",
    "with open('ids.csv', 'w', encoding='utf-8') as file:\n",
    "    file.writelines(filtered_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to Extract whether the tweet is a reply or not from elonmusk.csv\n",
    "\n",
    "def clean_line(line):\n",
    "    # Remove ambiguous characters but keep spaces, newlines, and commas\n",
    "    new_line = re.sub(r'[^\\w\\s,:\"@]', '', line)\n",
    "    if len(new_line.split(',')) < 2:\n",
    "        return ''\n",
    "    first_entry = new_line.split(',')[0]\n",
    "    second_entry = new_line.split(',')[1]\n",
    "    output_string = first_entry + ',' + second_entry\n",
    "    \n",
    "    if len(output_string) > 22:\n",
    "        s = output_string[21:]\n",
    "        if bool(re.match(r'^RT', s.strip())):\n",
    "            if output_string[-1] == '\\n':\n",
    "                return output_string\n",
    "            return output_string + '\\n'\n",
    "    return ''\n",
    "    \n",
    "\n",
    "# Read the CSV file with the specified encoding\n",
    "with open('elonmusk.csv', 'r', encoding='utf-8', errors='ignore') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Clean each line\n",
    "cleaned_lines = [clean_line(line) for line in lines[1:]]\n",
    "modified_lines = [line.rstrip('\\n') + '\"' + '\\n' if not line.rstrip('\\n').endswith('\"') else line for line in cleaned_lines]\n",
    "modified_lines = [line for line in modified_lines if not len(line) == 2]\n",
    "\n",
    "# Write the modified lines back to the CSV file\n",
    "with open('retweets.csv', 'w', encoding='utf-8') as file:\n",
    "    file.writelines(modified_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @MarioNawfal:  BRAZILIAN X NEWS OUTLET LATEST CENSORSHIP VICTIM\n"
     ]
    }
   ],
   "source": [
    "def get_retweeted_from(s):\n",
    "    first_entry = s.split(':')[0]\n",
    "    return first_entry[4:]\n",
    "\n",
    "df = pd.read_csv('retweets.csv', header=None)\n",
    "df.columns = ['ID', 'Tweet']\n",
    "df['Retweeted'] = df['Tweet'].apply(get_retweeted_from)\n",
    "\n",
    "df.head(20)\n",
    "print(df['Tweet'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.read_csv('ids.csv', header=None)\n",
    "ids.columns = ['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Tweet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ricks\\Desktop\\Polymarket_Stuff\\.conda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:175\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Tweet'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Read the retweets.csv file\u001b[39;00m\n\u001b[0;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretweets.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetweeted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTweet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(get_retweeted_from)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Merge the two DataFrames on the 'ID' column, keeping all IDs from ids\u001b[39;00m\n\u001b[0;32m     10\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(ids, df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ricks\\Desktop\\Polymarket_Stuff\\.conda\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\ricks\\Desktop\\Polymarket_Stuff\\.conda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Tweet'"
     ]
    }
   ],
   "source": [
    "# Read the ids.csv file\n",
    "ids = pd.read_csv('ids.csv', header=None)\n",
    "ids.columns = ['ID']\n",
    "\n",
    "# Read the retweets.csv file\n",
    "df = pd.read_csv('retweets.csv', header=None)\n",
    "df.columns = ['ID', 'Tweet']\n",
    "df['Retweeted'] = df['Tweet'].apply(get_retweeted_from)\n",
    "\n",
    "# Merge the two DataFrames on the 'ID' column, keeping all IDs from ids\n",
    "merged_df = pd.merge(ids, df, on='ID', how='left')\n",
    "\n",
    "# Write the merged DataFrame to a new CSV file\n",
    "merged_df.head(20)\n",
    "\n",
    "# Write the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
